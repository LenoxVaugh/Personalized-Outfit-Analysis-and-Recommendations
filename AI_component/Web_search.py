# from bs4 import BeautifulSoup
# from selenium import webdriver
# from selenium.webdriver.edge.options import Options as EdgeOptions
# import time
# import sys
# import os
# # Configure Selenium for Edge
# # options = EdgeOptions()
# # options.add_argument("--headless")
# # options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36")
# # driver = webdriver.Edge(options=options)

# # # ·∫®n to√†n b·ªô log c·∫£nh b√°o h·ªá th·ªëng v√† selenium
# # os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
# # os.environ["PYTHONWARNINGS"] = "ignore"
# # sys.stderr = open(os.devnull, 'w')  # ·∫®n log l·ªói h·ªá th·ªëng (nh∆∞ DevTools...)
# def search_lazada(query):
# # C·∫•u h√¨nh c√°c t√πy ch·ªçn cho Microsoft Edge
#     options = EdgeOptions()
#     options.use_chromium = True
#     options.add_argument("--headless")  # Ch·∫ø ƒë·ªô headless
#     options.add_argument("--disable-gpu")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")

#     # Thi·∫øt l·∫≠p user-agent ƒë·ªÉ m√¥ ph·ªèng tr√¨nh duy·ªát th·∫≠t
#     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36")
#     driver = webdriver.Edge(options=options)
#     try:
#         # URL t√¨m ki·∫øm tr√™n Lazada (Lazada Vi·ªát Nam)
#         url = f"https://www.lazada.vn/catalog/?q={query}"
#         driver.get(url)
        
#         # ƒê·ª£i trang t·∫£i n·ªôi dung (c√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh th·ªùi gian t√πy theo t·ªëc ƒë·ªô m·∫°ng)
#         time.sleep(5)
        
#         # Cu·ªôn trang xu·ªëng d∆∞·ªõi ƒë·ªÉ t·∫£i th√™m s·∫£n ph·∫©m (n·∫øu c·∫ßn)
#         driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
#         time.sleep(3)
        
#         # L·∫•y HTML trang hi·ªán t·∫°i v√† parse b·∫±ng BeautifulSoup
#         soup = BeautifulSoup(driver.page_source, 'html.parser')
#         products = []
        
#         # Lazada th∆∞·ªùng hi·ªÉn th·ªã s·∫£n ph·∫©m trong c√°c th·∫ª <a> c√≥ li√™n k·∫øt ƒë·∫øn s·∫£n ph·∫©m
#         # L·ªçc ra nh·ªØng link c√≥ ch·ª©a "/products/"
#         for a_tag in soup.find_all('a', href=True):
#             link = a_tag['href']
#             if '/products/' not in link:
#                 continue
            
#             # L·∫•y ti√™u ƒë·ªÅ s·∫£n ph·∫©m t·ª´ thu·ªôc t√≠nh 'title' ho·∫∑c t·ª´ th·∫ª <img alt="">
#             title = a_tag.get('title')
#             if not title:
#                 img_tag = a_tag.find('img', alt=True)
#                 if img_tag:
#                     title = img_tag.get('alt')
            
#             if not title:
#                 continue
            
#             # N·∫øu link kh√¥ng c√≥ giao th·ª©c, th√™m "https:"
#             if not link.startswith('http'):
#                 link = "https:" + link
            
#             products.append({"title": title, "link": link})
        
#         return products
#     finally:
#         # ƒê·∫£m b·∫£o ƒë√≥ng tr√¨nh duy·ªát sau khi ho√†n th√†nh
#         driver.quit()
# if __name__ == "__main__":
#     query = "√°o thun"  # V√≠ d·ª•: t√¨m ki·∫øm "√°o thun"
#     products = search_lazada(query)
#     print("Found products:")
#     for product in products:
#         print(f"Title: {product['title']}")
#         print(f"Link: {product['link']}")
#         print("-" * 30)

from bs4 import BeautifulSoup
import time
import os
import pickle
from selenium import webdriver
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def save_cookies(driver, filename="cookies.pkl"):
    with open(filename, "wb") as cookie_file:
        pickle.dump(driver.get_cookies(), cookie_file)

def load_cookies(driver, filename="cookies.pkl"):
    if os.path.exists(filename):
        with open(filename, "rb") as cookie_file:
            cookies = pickle.load(cookie_file)
        for cookie in cookies:
            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print("‚ùó Cookie error:", e)

def search_lazada(query):
    options = EdgeOptions()
    options.use_chromium = True

    # Ch·∫°y ho√†n to√†n ·∫©n kh√¥ng c·ª≠a s·ªï
    options.add_argument("--headless=new")  # ƒê·∫£m b·∫£o d√πng ch·∫ø ƒë·ªô headless m·ªõi
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36")

    # Kh√¥ng gi·ªØ c·ª≠a s·ªï sau khi ch·∫°y
    options.add_experimental_option("detach", False)

    # T·∫°o WebDriver
    driver = webdriver.Edge(options=options)

    try:
        driver.get("https://www.lazada.vn/")
        time.sleep(1)

        load_cookies(driver)
        driver.refresh()
        time.sleep(1)

        search_url = f"https://www.lazada.vn/catalog/?q={query.replace(' ', '+')}"
        driver.get(search_url)

        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div[data-qa-locator='product-item']"))
        )

        save_cookies(driver)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        items = soup.select("div[data-qa-locator='product-item']")
        results = []

        for item in items:
            a_tag = item.find("a", href=True)
            if a_tag:
                link = a_tag.get("href")
                if not link.startswith("http"):
                    link = "https:" + link
                title = a_tag.get("title") or a_tag.find("img").get("alt", "")
                if title:
                    results.append({
                        "title": title.strip(),
                        "link": link.strip()
                    })

        return results

    except Exception as e:
        print("‚ùå L·ªói:", e)
        return []

    finally:
        driver.quit()

# # Test
# if __name__ == "__main__":
#     search_terms = ["√°o thun tr·∫Øng", "√°o kho√°c bomber nam"]
#     for search_term in search_terms:
#         print(f"üîç T√¨m ki·∫øm: {search_term}")
#         results = search_lazada(search_term)
        
#         if results:
#             print("‚úÖ Found products:")
#             for i, product in enumerate(results[:5], 1):
#                 print(f"{i}. {product['title']}")
#                 print(f"   üîó {product['link']}\n")
#         else:
#             print("‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m.")
